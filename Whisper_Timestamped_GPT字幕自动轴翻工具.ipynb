{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPbAwbOdSakq7r4l8GCMfLU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MogoWhite/Subtitle_Auto_Alignment_and_Translation/blob/main/Whisper_Timestamped_GPT%E5%AD%97%E5%B9%95%E8%87%AA%E5%8A%A8%E8%BD%B4%E7%BF%BB%E5%B7%A5%E5%85%B7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Whisper_Timestamped_GPT字幕自动轴翻工具\n",
        "### 具体用来完成以下三个任务\n",
        "1.   使用whisper的扩展库whisper_timestamped，进行语音转文字及单词级时间轴校准，并生成SRT格式的字幕文件。\n",
        "\n",
        "\n",
        "2.   调整字幕文件（SRT格式）中字幕的起始和结束时间的功能：\n",
        "\n",
        "    1.   将字幕的开始时间向前或向后移动。\n",
        "    2.   将字幕的结束时间向后移动。\n",
        "    3.   调整相邻字幕之间的时间间隔。\n",
        "\n",
        "\n",
        "3.  调用api实现以下功能：\n",
        "    1.   将字幕文件逐行翻译为目标语言。\n",
        "    2.   支持生成双语字幕或仅翻译后的字幕。\n",
        "    3.   支持导出为 ASS 或 SRT 格式。\n",
        "    4.   增加多线程GPT处理。\n",
        "    5.   增加多行输入，可以更好的联系上下文。\n",
        "    6.   调整prompt，一定程度提高专有名词翻译精度。\n",
        "\n",
        "4.  最后想了想，还是提取分行的文字直接扔到chatgpt翻译更方便，还免费。\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   首先使用下面的网站，从视频分离出mp3格式的音频。\n",
        "\n",
        "       https://online-audio-converter.com\n",
        "\n",
        "\n",
        "*   然后将音频，从本地拖拽到本页面左侧文件的位置，或使用文件栏左上角的**上传到会话存储空间**按钮上传文件。\n",
        "![image.png](https://i.imgur.com/PoWwdAo.png)\n",
        "\n",
        "\n",
        "*   接下来复制文件路径，用于输入后面的地址框。\n",
        "![image.png](https://i.imgur.com/t0Lkqwr.png)\n",
        "\n",
        "*  选择GPU\n",
        "![image.png](https://i.imgur.com/CVhHPVC.png)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Xk6n3IRtfkDT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gFvm-AG6-7wb"
      },
      "outputs": [],
      "source": [
        "#@title 安装运行库\n",
        "\n",
        "!pip3 install ffmpeg\n",
        "!pip3 install git+https://github.com/linto-ai/whisper-timestamped\n",
        "!pip3 install onnxruntime torchaudio\n",
        "!pip3 install pysrt\n",
        "!pip3 install yt-dlp\n",
        "!pip3 install openai  \n",
        "!pip3 install pysubs2\n",
        "!pip3 install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 测试 cuda 和 whisper_timestamped\n",
        "import torch\n",
        "import whisper_timestamped\n",
        "print(torch.cuda.is_available())\n",
        "help(whisper_timestamped.transcribe)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IvH5nQH2_TyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3ZTAE9IGQWi",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 加载whisper模型\n",
        "import torch\n",
        "import whisper_timestamped\n",
        "\n",
        "model = whisper_timestamped.load_model(\"large-v2\", device=\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOtq2ysV-Aj6"
      },
      "outputs": [],
      "source": [
        "#@title 运行whisper_timestamped 语音转文字 { display-mode: \"form\" }\n",
        "\n",
        "\n",
        "# @markdown **要填！！！** input_file: 输入音频文件路径\n",
        "# @markdown </br>\n",
        "# @markdown </br> input_prompt: 第一句话的提示，影响第一句话的生成，默认留空\n",
        "# @markdown </br>\n",
        "# @markdown </br> length_penalty: 调节生成的句子的长度，值增大输出的句子有缩短倾向\n",
        "# @markdown </br>\n",
        "# @markdown </br> min_sentence_duration: 一句话持续时间的最小值\n",
        "\n",
        "\n",
        "import pysrt\n",
        "import torch\n",
        "from datetime import timedelta\n",
        "\n",
        "def timedelta_to_SubRipTime(td):\n",
        "    \"\"\"\n",
        "    Converts a timedelta object to a SubRipTime object.\n",
        "    \n",
        "    Args:\n",
        "    td (timedelta): A timedelta object representing a duration.\n",
        "\n",
        "    Returns:\n",
        "    pysrt.srttime.SubRipTime: A SubRipTime object representing the same duration as the input timedelta.\n",
        "    \"\"\"\n",
        "    total_seconds = td.total_seconds()\n",
        "    hours, remainder = divmod(total_seconds, 3600)\n",
        "    minutes, seconds = divmod(remainder, 60)\n",
        "    return pysrt.srttime.SubRipTime(int(hours), int(minutes), int(seconds), int(td.microseconds // 1000))\n",
        "\n",
        "input_file = \"/content/kuboasu.mp3\" # @param {type:\"string\"}\n",
        "audio = whisper_timestamped.load_audio(input_file)\n",
        "input_prompt = \"\" # @param {type:\"string\"}\n",
        "\n",
        "result = whisper_timestamped.transcribe(\n",
        "    model=model,\n",
        "    audio=audio,\n",
        "    language='ja',\n",
        "    task='transcribe',\n",
        "    remove_punctuation_from_words=True,\n",
        "    seed=0,\n",
        "    vad=True,\n",
        "    #detect_disfluencies=True,\n",
        "    trust_whisper_timestamps=False,\n",
        "    length_penalty=1 #@param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "    ,\n",
        "    #长度惩罚因子\n",
        "    initial_prompt=input_prompt,\n",
        "    suppress_tokens='-1',\n",
        "    min_word_duration=0.02 #@param {type:\"slider\", min:0.00, max:0.10, step:0.01}\n",
        "    ,\n",
        "    #compression_ratio_threshold=5.0,\n",
        "    #logprob_threshold=-3.0\n",
        ")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "segments = result[\"segments\"]\n",
        "subtitles = pysrt.SubRipFile()\n",
        "\n",
        "for data in segments:\n",
        "    index = data[\"id\"] + 1\n",
        "    start = timedelta(seconds=data[\"start\"])\n",
        "    end = timedelta(seconds=data[\"end\"])\n",
        "    text = data[\"text\"]\n",
        "    sub = pysrt.SubRipItem(index=index,\n",
        "                           start=timedelta_to_SubRipTime(start),\n",
        "                           end=timedelta_to_SubRipTime(end),\n",
        "                           text=text)\n",
        "\n",
        "    subtitles.append(sub)\n",
        "\n",
        "base_name = input_file.rsplit('.', 1)[0]\n",
        "output_file = base_name + \"_output.srt\"\n",
        "subtitles.save(output_file, encoding=\"utf-8\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z882JBDthSRM"
      },
      "outputs": [],
      "source": [
        "#@title 字幕调轴 { display-mode: \"form\" }\n",
        "\n",
        "# @markdown </br>shift_start_ms: 开始时间轴上移动的毫秒数。负值表示字幕开始时间提前，正值表示字幕开始时间延后。\n",
        "# @markdown </br>\n",
        "# @markdown </br>shift_end_ms: 结束时间轴上移动的毫秒数。正值表示字幕结束时间延后，负值表示字幕结束时间提前。\n",
        "# @markdown </br>\n",
        "# @markdown </br>min_gap: 两个连续字幕之间的最小时间间隔。如果间隔小于此值，当前字幕的结束时间将延长以满足最小间隔要求。\n",
        "\n",
        "\n",
        "input_srt_file = base_name + \"_output.srt\"\n",
        "final_output_srt_file = base_name + \"_adjusted.srt\"\n",
        "shift_start_ms = -10 #@param {type:\"slider\", min:-100, max:0, step:10}\n",
        "shift_end_ms = 300 #@param {type:\"slider\", min:0, max:500, step:50}\n",
        "min_gap = 300 #@param {type:\"slider\", min:0, max:500, step:50}\n",
        "\n",
        "\n",
        "import pysrt\n",
        "import datetime\n",
        "from datetime import timedelta\n",
        "\n",
        "def timedelta_to_subriptime(delta):\n",
        "    \"\"\"\n",
        "    Converts a timedelta object to a SubRipTime object.\n",
        "    \n",
        "    Args:\n",
        "    delta (timedelta): A timedelta object representing a duration.\n",
        "\n",
        "    Returns:\n",
        "    pysrt.SubRipTime: A SubRipTime object representing the same duration as the input timedelta.\n",
        "    \"\"\"\n",
        "    return pysrt.SubRipTime(hours=delta.days * 24 + delta.seconds // 3600, minutes=(delta.seconds // 60) % 60, seconds=delta.seconds % 60, milliseconds=delta.microseconds // 1000)\n",
        "\n",
        "def shift_start_time(subs, milliseconds):\n",
        "    \"\"\"\n",
        "    Shifts the start times of subtitles by a given number of milliseconds.\n",
        "\n",
        "    Args:\n",
        "    subs (list): A list of SubRipItem objects representing subtitles.\n",
        "    milliseconds (int): The number of milliseconds to shift the start times.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of updated SubRipItem objects with shifted start times.\n",
        "    \"\"\"\n",
        "    for i in range(len(subs)):\n",
        "        if i == 0 or subs[i].start != subs[i - 1].end:\n",
        "            new_start_time = subs[i].start + timedelta_to_subriptime(datetime.timedelta(milliseconds=milliseconds))\n",
        "            if i > 0 and new_start_time < subs[i - 1].end:\n",
        "                new_start_time = subs[i - 1].end\n",
        "            subs[i].start = new_start_time\n",
        "    return subs\n",
        "\n",
        "def shift_end_time(subs, milliseconds):\n",
        "    \"\"\"\n",
        "    Shifts the end times of subtitles by a given number of milliseconds.\n",
        "\n",
        "    Args:\n",
        "    subs (list): A list of SubRipItem objects representing subtitles.\n",
        "    milliseconds (int): The number of milliseconds to shift the end times.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of updated SubRipItem objects with shifted end times.\n",
        "    \"\"\"\n",
        "    for i in range(len(subs) - 1):\n",
        "        if subs[i].end != subs[i + 1].start:\n",
        "            new_end_time = subs[i].end + timedelta_to_subriptime(datetime.timedelta(milliseconds=milliseconds))\n",
        "            if new_end_time > subs[i + 1].start:\n",
        "                new_end_time = subs[i + 1].start\n",
        "            subs[i].end = new_end_time\n",
        "    return subs\n",
        "\n",
        "def adjust_subtitle_timing(subs, min_gap=300):\n",
        "    \"\"\"\n",
        "    Adjusts the timing of subtitles to ensure a minimum gap between them.\n",
        "\n",
        "    Args:\n",
        "    subs (list): A list of SubRipItem objects representing subtitles.\n",
        "    min_gap (int, optional): The minimum gap in milliseconds between subtitles. Defaults to 300.\n",
        "\n",
        "    Returns:\n",
        "    list: A\n",
        "    for i in range(len(subs) - 1):\n",
        "        current_sub = subs[i]\n",
        "        next_sub = subs[i + 1]\n",
        "        gap = next_sub.start - current_sub.end\n",
        "\n",
        "        if 0 < gap < min_gap:\n",
        "            current_sub.end = next_sub.start\n",
        "\n",
        "    return subs\n",
        "\n",
        "def process_subtitle_file(input_srt_file, output_srt_file, shift_start_ms, shift_end_ms, min_gap):\n",
        "    \"\"\"\n",
        "    Processes a subtitle file by shifting start and end times and adjusting the timing between subtitles.\n",
        "\n",
        "    Args:\n",
        "    input_srt_file (str): The input subtitle file (SRT format).\n",
        "    output_srt_file (str): The output subtitle file with modified timings (SRT format).\n",
        "    shift_start_ms (int): The number of milliseconds to shift the start times.\n",
        "    shift_end_ms (int): The number of milliseconds to shift the end times.\n",
        "    min_gap (int): The minimum\n",
        "\n",
        "    subs = pysrt.open(input_srt_file)\n",
        "\n",
        "    subs = shift_start_time(subs, shift_start_ms)\n",
        "\n",
        "    subs = shift_end_time(subs, shift_end_ms)\n",
        "\n",
        "    subs = adjust_subtitle_timing(subs, min_gap)\n",
        "\n",
        "    subs.save(output_srt_file, encoding='utf-8')\n",
        "\n",
        "# 调用函数处理字幕文件\n",
        "# ... (代码开头部分保持不变)\n",
        "\n",
        "process_subtitle_file(input_srt_file, final_output_srt_file, shift_start_ms, shift_end_ms, min_gap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8StHDYJKFXI",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 可跳过！！！ SRT字幕文件转ASS字幕文件 附加字幕样式\n",
        "\n",
        "# @markdown style_type: 字幕组样式\n",
        "\n",
        "\n",
        "\n",
        "style_type = \"石森璃花\" # @param [\"井上和\",\"石森璃花\"]\n",
        "input_srt = final_output_srt_file\n",
        "output_ass_file = base_name + \"_output.ass\"\n",
        "\n",
        "def srt_to_ass(input_srt, output_ass, style_type):\n",
        "    with open(input_srt, 'r', encoding='utf-8') as f:\n",
        "        srt_contents = f.read()\n",
        "\n",
        "    srt_lines = srt_contents.split('\\n')\n",
        "    ass_dialogues = []\n",
        "\n",
        "    if style_type == '井上和':\n",
        "        ass_header = (\n",
        "            \"[Script Info]\\n\"\n",
        "            \"; Script generated by Aegisub 9212-dev-3a38bf16a\\n\"\n",
        "            \"; http://www.aegisub.org/\\n\"\n",
        "            \"Title: Default Aegisub file\\n\"\n",
        "            \"ScriptType: v4.00+\\n\"\n",
        "            \"WrapStyle: 0\\n\"\n",
        "            \"ScaledBorderAndShadow: yes\\n\"\n",
        "            \"YCbCr Matrix: None\\n\"\n",
        "            \"PlayResX: 1920\\n\"\n",
        "            \"PlayResY: 1080\\n\"\n",
        "            \"\\n\"\n",
        "            \"[Aegisub Project Garbage]\\n\"\n",
        "            \"Last Style Storage: hinaai\\n\"\n",
        "            \"Video Zoom Percent: 0.875000\\n\"\n",
        "            \"Scroll Position: 63\\n\"\n",
        "            \"\\n\"\n",
        "            \"[V4+ Styles]\\n\"\n",
        "            \"Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\\n\"\n",
        "            \"Style: 井上和,思源黑体 CN,80,&H00FFFFFF,&H000000FF,&H030000FF,&HFF000000,-1,0,0,0,100,100,1.5,0,1,3,0,2,10,10,10,1\\n\"\n",
        "            \"Style: staff,思源黑体 CN,55,&H00FFFFFF,&H00FFFFFF,&H34000000,&H00000000,-1,0,0,0,100,100,3,0,1,2.5,0,7,16,13,4,1\\n\"\n",
        "            \"Style: 水印,悦黑 - yolan,30,&H73FFFFFF,&HFAFFFFFF,&H00FFFFFF,&HD1000300,-1,0,0,0,104,105,5,0,1,0,1.6,9,11,11,11,1\\n\"\n",
        "            \"Style: 屏字,思源黑体 CN,70,&H00FFFFFF,&H000019FF,&H00000000,&H00000000,-1,0,0,0,100,100,2,0,1,3,0,2,11,11,11,1\\n\"\n",
        "            \"Style: 上注释,思源黑体 CN,55,&H00FFFFFF,&H000019FF,&H1E000000,&H9E000000,-1,0,0,0,100,100,3,0,1,3,2,8,11,11,11,1\\n\"\n",
        "            \"Style: 竖,@思源黑体 CN,190,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,-1,0,0,0,100,100,10,-90,1,3,0,5,11,11,11,1\\n\"\n",
        "            \"\\n\"\n",
        "            \"[Events]\\n\"\n",
        "            \"Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\\n\"\n",
        "        )\n",
        "    else:  # style_type == 'sslh'\n",
        "        ass_header = (\n",
        "            \"[Script Info]\\n\"\n",
        "            \"; Script generated by Aegisub 9212-dev-3a38bf16a\\n\"\n",
        "            \"; http://www.aegisub.org/\\n\"\n",
        "            \"Title: Default Aegisub file\\n\"\n",
        "            \"ScriptType: v4.00+\\n\"\n",
        "            \"WrapStyle: 0\\n\"\n",
        "            \"ScaledBorderAndShadow: yes\\n\"\n",
        "            \"YCbCr Matrix: None\\n\"\n",
        "            \"PlayResX: 1920\\n\"\n",
        "            \"PlayResY: 1080\\n\"\n",
        "            \"\\n\"\n",
        "            \"[Aegisub Project Garbage]\\n\"\n",
        "            \"Last Style Storage: 璃花\\n\"\n",
        "            \"Video Zoom Percent: 0.500000\\n\"\n",
        "            \"Active Line: 1\\n\"\n",
        "            \"\\n\"\n",
        "            \"[V4+ Styles]\\n\"\n",
        "            \"Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\\n\"\n",
        "            \"Style: 对话 1080P,思源黑体 CN Medium,75,&H00FFFFFF,&H000000FF,&H00EE49FA,&H002BE257,-1,0,0,0,100,100,4,0,1,4,3,2,10,10,10,1\\n\"\n",
        "            \"Style: staff 1080P,方正准圆简体,45,&H00FFFFFF,&H000000FF,&H00EE49FA,&H002BE257,-1,0,0,0,100,100,4,0,1,4,3,7,15,15,10,1\\n\"\n",
        "            \"Style: 屏字 1080P,方正兰亭圆_GBK,60,&H00FFFFFF,&H000019FF,&H00000000,&H00000000,-1,0,0,0,100,100,4,0,1,4,0,5,10,10,10,1\\n\"\n",
        "            \"Style: 注释 1080P,等线,50,&H00FFFFFF,&H000000FF,&H00F67DFF,&H002BE257,-1,0,0,0,100,100,4,0,1,4,3,8,10,10,15,1\\n\"\n",
        "            \"Style: 对话 720P,思源黑体 CN Medium,50,&H00FFFFFF,&H000000FF,&H00EE49FA,&H002BE257,-1,0,0,0,100,100,4,0,1,4,3,2,10,10,10,1\\n\"\n",
        "            \"Style: staff 720P,方正准圆简体,30,&H00FFFFFF,&H000000FF,&H00EE49FA,&H002BE257,-1,0,0,0,100,100,4,0,1,4,3,7,15,15,10,1\\n\"\n",
        "            \"Style: 屏字 720P,方正兰亭圆_GBK,40,&H00FFFFFF,&H000019FF,&H00000000,&H00000000,-1,0,0,0,100,100,4,0,1,4,0,5,10,10,10,1\\n\"\n",
        "            \"Style: 注释 720P,等线,33,&H00FFFFFF,&H000000FF,&H00F67DFF,&H002BE257,-1,0,0,0,100,100,4,0,1,4,3,8,10,10,15,1\\n\"\n",
        "            \"\\n\"\n",
        "            \"[Events]\\n\"\n",
        "            \"Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\\n\"\n",
        "        )\n",
        "\n",
        "    for i in range(0, len(srt_lines), 4):\n",
        "        if srt_lines[i].isdigit():\n",
        "            start_time, end_time = srt_lines[i+1].split(\" --> \")\n",
        "            ass_start_time = start_time.replace(\",\", \".\")\n",
        "            ass_end_time = end_time.replace(\",\", \".\")\n",
        "\n",
        "            dialogue_text = srt_lines[i+2].replace(\"\\\\N\", \"\\n\")\n",
        "            dialogue_line = f\"Dialogue: 0,{ass_start_time},{ass_end_time},Default,,0,0,0,,{dialogue_text}\"\n",
        "            ass_dialogues.append(dialogue_line)\n",
        "\n",
        "    with open(output_ass, 'w', encoding='utf-8') as f:\n",
        "        f.write(ass_header)\n",
        "        f.write('\\n'.join(ass_dialogues))\n",
        "\n",
        "# 使用函数将 SRT 文件转换为 ASS 文件\n",
        "\n",
        "srt_to_ass(input_srt, output_ass_file, style_type)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title （可选，没有api，想使用免费翻译，请跳过这一段）并行GPT处理  { display-mode: \"form\" }\n",
        "\n",
        "\n",
        "# @markdown **要填！！！adjusted后缀的字幕文件地址**  sub_path: 待翻译的字幕文件路径（字符串）\n",
        "# @markdown </br>\n",
        "# @markdown </br>**要填！！！**openai_key: OpenAI API 密钥（字符串）\n",
        "# @markdown </br>\n",
        "# @markdown </br>target_language: 目标语言，例如 \"zh-hans\"（简体中文）或 \"english\"（英语）\n",
        "# @markdown </br>\n",
        "# @markdown </br>content_related_text: GPT-4 用于翻译的提示，如专有名词的翻译方式等，现在只对第一批输入的行有效，例：请把 あすか 翻译为 飞鸟.（字符串）\n",
        "# @markdown </br>\n",
        "# @markdown </br>temperature: GPT-4 API 的温度值，控制输出结果的随机性（0 到 1.0 之间的浮点数）\n",
        "# @markdown </br>\n",
        "# @markdown </br>output_mode: 输出模式，\"translated\"（仅翻译后的字幕）或 \"bilingual\"（双语字幕）\n",
        "# @markdown </br>\n",
        "# @markdown </br>model_name: GPT模型，'gpt-3.5-turbo'或'gpt-4'\n",
        "# @markdown </br>\n",
        "# @markdown </br>output_format: 输出文件格式，\"ass\"（ASS 字幕）或 \"srt\"（SRT 字幕）\n",
        "# @markdown </br>\n",
        "# @markdown </br>batch_size: 每次输入的行数，增大每行之间内容的关联性增加，但增加输出出错的可能性，建议为全部行数的1/2或1/4，不要超过50（1 到 100 之间的整数）\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "使用 GPT-4 API 翻译字幕文件\n",
        "\n",
        "功能：\n",
        "    1. 将字幕文件逐行翻译为目标语言。\n",
        "    2. 支持生成双语字幕或仅翻译后的字幕。\n",
        "    3. 支持导出为 ASS 或 SRT 格式。\n",
        "    4. 增加多线程GPT处理。\n",
        "    5. 增加多行输入，可以更好的联系上下文。\n",
        "\n",
        "输入：\n",
        "    sub_path：待翻译的字幕文件路径（字符串）。\n",
        "    openai_key：OpenAI API 密钥（字符串）。\n",
        "    target_language：目标语言，例如 \"zh-hans\"（简体中文）或 \"english\"（英语）。\n",
        "    content_related_text：GPT-4 用于翻译的提示（字符串）。\n",
        "    temperature：GPT-4 API 的温度值，控制输出结果的随机性（0 到 1.0 之间的浮点数）。\n",
        "    output_mode：输出模式，\"translated\"（仅翻译后的字幕）或 \"bilingual\"（双语字幕）。\n",
        "    model_name: GPT模型，'gpt-3.5-turbo'或'gpt-4'\n",
        "    output_format：输出文件格式，\"ass\"（ASS 字幕）或 \"srt\"（SRT 字幕）。\n",
        "    batch_size：每次输入的行数（10 到 100 之间的整数）\n",
        "\n",
        "输出：\n",
        "    翻译后的字幕文件（ASS 或 SRT 格式）。\n",
        "\n",
        "示例：\n",
        "    sub_path = '/content/output_adjusted.srt'\n",
        "    openai_key = 'your_openai_api_key'\n",
        "    target_language = 'zh-hans'\n",
        "    content_related_text = \"You are a language expert. ...\"\n",
        "    temperature = 0.6\n",
        "    output_mode= 'bilingual'\n",
        "    model_name= 'gpt-3.5-turbo'\n",
        "    output_format = \"srt\"\n",
        "    batch_size=1\n",
        "\n",
        "    运行脚本后，会生成一个双语字幕文件 \"output_adjusted_bilingual_translation.srt\"。\n",
        "\"\"\"\n",
        "\n",
        "sub_path = '/content/kuboasu_output.ass'  # @param {type:\"string\"}\n",
        "openai_key = ''  # @param {type:\"string\"}\n",
        "target_language = 'zh-hans'  # @param [\"zh-hans\",\"english\"]\n",
        "\n",
        "prompt = \"You are a language expert. Your task is to translate the input subtitle text, sentence by sentence, into the user specified target language. However, please utilize the context to improve the accuracy and quality of translation. Be aware that the input text may contain typos and grammar mistakes; utilize the context to correct the translation. Please return only translated content and do not include the original text. Preserve the \\\"|||\\\" separator in the output. Do not use any punctuation around the returned text. Do not translate people's names and leave them in the original language.\" # @param {type:\"string\"}\n",
        "\n",
        "temperature = 0.6  # @param {type:\"slider\", min:0, max:1.0, step:0.1}\n",
        "output_mode= 'translated' # @param [\"translated\",\"bilingual\"]\n",
        "model_name= 'gpt-3.5-turbo' # @param [\"gpt-4\",\"gpt-3.5-turbo\"]\n",
        "output_format = \"srt\"  # @param [\"ass\",\"srt\"]\n",
        "batch_size=100 #@param {type:\"slider\", min:10, max:100, step:1}\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import codecs\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "\n",
        "sub_name = sub_path\n",
        "sub_basename = Path(sub_name).stem\n",
        "\n",
        "import openai\n",
        "import pysubs2\n",
        "\n",
        "clear_output()\n",
        "\n",
        "class ChatGPTAPI():\n",
        "    def __init__(self, key, language, prompt, temperature, model):\n",
        "        \"\"\"\n",
        "        Initializes the ChatGPTAPI class with the given API key, target language, prompt, temperature, and model name.\n",
        "\n",
        "        Args:\n",
        "        key (str): The API key for OpenAI.\n",
        "        language (str): The target language for translation.\n",
        "        prompt (str): The system prompt to set the context for translation.\n",
        "        temperature (float): The temperature for controlling randomness during sampling.\n",
        "        model_name (str): The name of the GPT model to use for translation.\n",
        "        \"\"\"\n",
        "        self.key = key\n",
        "        self.language = language\n",
        "        self.prompt = prompt\n",
        "        self.temperature = temperature\n",
        "        self.model = model_name\n",
        "\n",
        "    def translate(self, text):\n",
        "        \"\"\"\n",
        "        Translates the given text to the target language using the OpenAI GPT model.\n",
        "\n",
        "        Args:\n",
        "        text (str): The input text to be translated.\n",
        "\n",
        "        Returns:\n",
        "        str: The translated text in the target language.\n",
        "        \"\"\"\n",
        "        openai.api_key = self.key\n",
        "        try:\n",
        "            completion = openai.ChatCompletion.create(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": f'{self.prompt}'\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\":\"user\",\n",
        "                        \"content\": f\"Original text:`{text}`. Target language: {self.language}\"\n",
        "                    }\n",
        "                ],\n",
        "                temperature=self.temperature\n",
        "            )\n",
        "            t_text = (\n",
        "                completion[\"choices\"][0]\n",
        "                .get(\"message\")\n",
        "                .get(\"content\")\n",
        "                .encode(\"utf8\")\n",
        "                .decode()\n",
        "            )\n",
        "        except Exception as e:\n",
        "            sleep_time = int(60)\n",
        "            time.sleep(sleep_time)\n",
        "            print(e, f\"will sleep  {sleep_time} seconds\")\n",
        "            openai.api_key = self.key\n",
        "            completion = openai.ChatCompletion.create(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": f'{self.prompt}'\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": f\"Original text:`{text}`. Target language: {self.language}\"\n",
        "                    }\n",
        "                ],\n",
        "                temperature=self.temperature\n",
        "            )\n",
        "            t_text = (\n",
        "                completion[\"choices\"][0]\n",
        "                .get(\"message\")\n",
        "                .get(\"content\")\n",
        "                .encode(\"utf8\")\n",
        "                .decode()\n",
        "            )\n",
        "        return t_text\n",
        "\n",
        "class SubtitleTranslator():\n",
        "    def __init__(self, sub_src, model, key, language, prompt, temperature, output_mode='bilingual'):\n",
        "        \"\"\"\n",
        "        Initializes the SubtitleTranslator class with the given subtitle source file, translation model, API key, target language, system prompt, temperature, and output mode.\n",
        "\n",
        "        Args:\n",
        "        sub_src (str): The path to the subtitle source file (SRT or ASS format).\n",
        "        model (class): The translation model class.\n",
        "        key (str): The API key for the translation model.\n",
        "        language (str): The target language for translation.\n",
        "        prompt (str): The system prompt to set the context for translation.\n",
        "        temperature (float): The temperature for controlling randomness during sampling.\n",
        "        output_mode (str): The mode for outputting translated subtitles ('bilingual' or 'translated'). Default is 'bilingual'.\n",
        "        \"\"\"\n",
        "        self.sub_src = sub_src\n",
        "        self.translate_model = model(key, language, prompt, temperature, model)\n",
        "        self.translations = []\n",
        "        self.output_mode = output_mode\n",
        "\n",
        "    def translate_by_line(self):\n",
        "        \"\"\"\n",
        "        Translates the subtitle lines using the translation model and generates a new subtitle file with translations.\n",
        "\n",
        "        Returns:\n",
        "        tuple: A tuple containing the translated subtitle file and a list of translated lines.\n",
        "        \"\"\"\n",
        "        sub_trans = pysubs2.load(self.sub_src)\n",
        "        total_lines = len(sub_trans)\n",
        "        lines_to_translate = []\n",
        "\n",
        "        # 新增一个列表，用于保存任务\n",
        "        tasks = []\n",
        "\n",
        "        with ThreadPoolExecutor() as executor:\n",
        "            with tqdm(total=total_lines, ncols=80) as pbar:\n",
        "              for i, line in enumerate(sub_trans):\n",
        "                  lines_to_translate.append(line.text)\n",
        "\n",
        "                  if (i + 1) % batch_size == 0 or i == total_lines - 1:\n",
        "                      combined_text = '|||'.join(lines_to_translate)\n",
        "                      # 将任务提交到线程池，并将任务添加到tasks列表\n",
        "                      task = executor.submit(self.translate_model.translate, combined_text)\n",
        "                      tasks.append((task, i, lines_to_translate))\n",
        "                      lines_to_translate = []\n",
        "\n",
        "              # 在线程池中处理任务\n",
        "              for task, i, lines_to_translate in tasks:\n",
        "                  try:\n",
        "                      translated_text = task.result()\n",
        "                      translated_lines = translated_text.split('|||')\n",
        "                      pbar.write(str(translated_lines))\n",
        "\n",
        "                      for j, t_line in enumerate(translated_lines):\n",
        "                          if self.output_mode == 'bilingual':\n",
        "                              sub_trans[i - len(lines_to_translate) + 1 + j].text += (r'\\N' + t_line)\n",
        "                          elif self.output_mode == 'translated':\n",
        "                              sub_trans[i - len(lines_to_translate) + 1 + j].text = t_line\n",
        "                          self.translations.append(t_line)\n",
        "                      # 更新进度条\n",
        "                      pbar.update(len(lines_to_translate))\n",
        "                      pbar.refresh()\n",
        "                  except Exception as e:\n",
        "                      print(f\"Error occurred during translation: {e}\")\n",
        "                      pbar.update(len(lines_to_translate))\n",
        "            return sub_trans, self.translations\n",
        "\n",
        "\n",
        "\n",
        "translate_model = ChatGPTAPI\n",
        "\n",
        "assert translate_model is not None, \"unsupported model\"\n",
        "OPENAI_API_KEY = openai_key\n",
        "\n",
        "if not OPENAI_API_KEY:\n",
        "    raise Exception(\n",
        "        \"OpenAI API key not provided, please google how to obtain it\"\n",
        "    )\n",
        "\n",
        "t = SubtitleTranslator(\n",
        "    sub_src=sub_name,\n",
        "    model=translate_model,\n",
        "    key=OPENAI_API_KEY,\n",
        "    language=target_language,\n",
        "    prompt=prompt,\n",
        "    temperature=temperature,\n",
        "    output_mode=output_mode)\n",
        "\n",
        "translation, _ = t.translate_by_line()\n",
        "\n",
        "if output_format == 'ass':\n",
        "    translation.save(sub_basename +'_'+ output_mode +'_translation.ass')\n",
        "    files.download(sub_basename +'_'+ output_mode + '_translation.ass')\n",
        "elif output_format == 'srt':\n",
        "    translation.save(sub_basename +'_'+ output_mode + '_translation.srt')\n",
        "    files.download(sub_basename +'_'+ output_mode + '_translation.srt')\n",
        "\n",
        "print('双语字幕生成完毕 All done!')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "ef4_Y7JPA3vC",
        "outputId": "e9ef89c1-2bc3-44f7-9c4f-ffe227ab51dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████| 56/56 [01:34<00:00,  1.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['明天香的写真集博物馆', '哎呀！', '哇，好漂亮', '马上就很漂亮', '最喜欢的剪辑是从一开始就喜欢的全男性', '哎呀，嘴巴好可爱', '因为嘴巴很可爱', 'T恤', '成年明天香的T恤', '啊，看起来好美味', '哎呀', '刷牙', '明天香果然嘴巴可爱', '明天香穿着休闲装', '露出额头的明天香', '新鲜', '好', '哎呀，这顶帽子真的很适合', '为什么？', '哇', '这套牛仔装超级可爱', '哎呀', '哇，好瘦', '只穿着牛仔衬衫', '啊，这是你说的第一款耳环', '浓重的唇膏最棒', '哎呀', '锁骨好漂亮', '超级漂亮', '感觉好像要被明天香生气', '明天香变成大人了', '明天香不要生气', '你看，三期生和明天香一起', '从十几岁开始就一直在一起', '变得很高兴', '明天香不要生气', '吃着冰淇淋', '啊，好可爱', '啊哈哈', '啊，但是也有孩子气的部分', '很高兴', '哇，眼睛的颜色', '好漂亮', '光线进入', '这看完就回来', '看标题博物馆', '哈', '这一本好棒', '明天香都被塞满了', '感觉像是调色盘的明天香', '喜欢什么颜色的明天香？', '那种感觉', '全部都可爱', '最棒的博物馆', '好可爱']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9f2d75e9-e185-45c2-b51f-9ad69538137a\", \"kuboasu_output_translated_translation.srt\", 3000)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "双语字幕生成完毕 All done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 字幕文字分行提取\n",
        "import pysubs2\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "def print_subtitles_with_separator(subtitle_file, lines_per_widget=25):\n",
        "    sub_data = pysubs2.load(subtitle_file)\n",
        "    separated_texts = []\n",
        "\n",
        "    for i in range(0, len(sub_data), lines_per_widget):\n",
        "        separated_lines = []\n",
        "        prompt = \"请将以下日语字幕文本逐句翻译成中文：\"\n",
        "        for line in sub_data[i:i + lines_per_widget]:\n",
        "            separated_lines.append(line.text)\n",
        "        combined_text = '|||'.join(separated_lines)\n",
        "        separated_texts.append(prompt + combined_text + \"。请利用上下文提高翻译的准确性和质量。请注意，输入文本可能包含错别字和语法错误；利用上下文来纠正翻译。请仅返回翻译后的内容，不要包含原始文本。请保留输出中的'|||'分隔符。不要在返回的文本中使用任何标点符号。不要翻译人名，保留原始语言。\")\n",
        "    return separated_texts\n",
        "\n",
        "# 使用您的字幕文件路径替换 '/content/misa_output.ass'\n",
        "# 如果你要使用 SRT 文件，只需更改文件路径\n",
        "subtitle_file = '/content/output_adjusted.srt'  # @param {type:\"string\"}\n",
        "\n",
        "# 修改这个值以更改每个文本窗口的行数\n",
        "lines_per_widget = 40  # @param {type:\"integer\"}\n",
        "\n",
        "separated_texts = print_subtitles_with_separator(subtitle_file, lines_per_widget)\n",
        "\n",
        "for idx, separated_text in enumerate(separated_texts):\n",
        "    # 创建一个 Text widget\n",
        "    text_widget = widgets.Textarea(\n",
        "        value=separated_text,\n",
        "        description=f'Output {idx + 1}:',\n",
        "        layout=widgets.Layout(width='100%', height='200px')\n",
        "    )\n",
        "\n",
        "    # 显示 Text widget\n",
        "    display(text_widget)\n"
      ],
      "metadata": {
        "id": "3RXEzIeDYWh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**上面的一段一段扔到chatgpt里：**\n"
      ],
      "metadata": {
        "id": "IOX0vQlyfOUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pysubs2\n",
        "\n",
        "def write_subtitles_from_separated_text(subtitle_file, separated_text, output_mode=\"translated\"):\n",
        "    sub_data = pysubs2.load(subtitle_file)\n",
        "    split_lines = separated_text.split('|||')\n",
        "\n",
        "    if len(sub_data) != len(split_lines):\n",
        "        print(\"Warning: Number of lines in the original subtitle file and separated text do not match.\")\n",
        "        return\n",
        "\n",
        "    for i, line in enumerate(sub_data):\n",
        "        if output_mode == \"bilingual\":\n",
        "            line.text += r'\\N' + split_lines[i]\n",
        "        elif output_mode == \"translated\":\n",
        "            line.text = split_lines[i]\n",
        "\n",
        "    sub_data.save(subtitle_file)\n",
        "\n",
        "# 使用您的字幕文件路径替换 'your_subtitle_file.ass'\n",
        "subtitle_file = '/content/enasu_output.ass' # @param {type:\"string\"}\n",
        "\n",
        "# 用 '|||' 连接的文本字符串\n",
        "separated_text = ' '  # @param {type:\"string\"}\n",
        "\n",
        "# 设置 output_mode 为 \"translated\" 或 \"bilingual\"\n",
        "output_mode = \"translated\"  # @param [\"translated\", \"bilingual\"]\n",
        "\n",
        "write_subtitles_from_separated_text(subtitle_file, separated_text, output_mode)\n"
      ],
      "metadata": {
        "id": "LlYjj2jjYWS2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}